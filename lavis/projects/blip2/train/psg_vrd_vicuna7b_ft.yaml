 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause



model:
  arch: blip2_vicuna_vrd
  model_type: base_psg
  
  use_grad_checkpoint: True
  freeze_vit: True
  
  llm_model: "/mnt/petrelfs/share_data/liuyuan/llm_weights/vicuna_weights_7b"

  load_finetuned: False
  pretrained: "/mnt/petrelfs/lirongjie/project/LAVIS/lavis/output/BLIP2/rel_detection_psg/20230530105-vicuna_vrd-partial_lyr_lora-6-train/checkpoint_2.pth"
  
  # pretrained: "/mnt/petrelfs/lirongjie/project/LAVIS/cache/ckpt/blip_instr/instruct_blip_vicuna7b_trimmed.pth"

  max_txt_len: 2048 # test time

  vit_precision: fp32

  max_objects: 8
  dump_pred: False
  dump_dir: "/mnt/petrelfs/lirongjie/project/LAVIS/lavis/output/BLIP/rel_detection_psg/vis_dump_val"
  
  num_coord_bin: 640
  # image_size: 364
  image_size: 224

  cate_dict_url: "/mnt/petrelfs/lirongjie/project/LAVIS/cache/psg/categories_dict.json"

  pos_adapter: True
  pos_adapter_tfmer_layer: 6

  finetune_strategy: partial_lyr_lora
  finetune_layer_num: 6

datasets:
  psg_rel_detection: # name of the dataset builder
    vis_processor:
        train:
          name: "blip_det_image_train"
          # image_size: 364
          image_size: 224
        eval:
          name: "blip_det_image_eval"
          # image_size: 364
          image_size: 224
    text_processor:
        train:
          name: "blip_caption"
          prompt: "a picture of "
        eval:
          name: "blip_caption"


run:
  task: relation_detection
  # optimizer

  lr_sched: "linear_warmup_cosine_lr"
  init_lr: 1e-5
  min_lr: 0
  warmup_lr: 1e-8
  warmup_steps: 500
  weight_decay: 0.05

  max_epoch: 50

  special_lr_param:
    name: ["llm_model.pos_adapter.pos_encoder", "llm_model.pos_adapter.pos_decoder", 
            "llm_model.pos_adapter.bbox_embed", "llm_model.pos_adapter.enc_input_proj",
            "llm_model.pos_adapter.ent_hs_input_proj", "llm_model.pos_adapter.conv_module"]
    # name: ["none", ]
    lr: 1e-5
    weight_decay: 1e-4

  batch_size_train: 2
  batch_size_eval: 2
  num_workers: 4

  save_epoch: 2

  max_len: 1500
  min_len: 64

  # max_len: 2048 # inference time
  # min_len: 300
  num_beams: 1

  seed: 42
  output_dir: "output/BLIP2/rel_detection_psg"

  experiments_mode: sggen # sggen sgcls
  generation_mode: sampling # sampling search


  amp: False
  resume_ckpt_path: null

  evaluate: False 
  train_splits: ["train"]
  # train_splits: ["train_zs_pred"]
  # train_splits: ["train_zs_trip"]
  test_splits: ["test"]
  valid_splits: ["val"]
  # valid_splits: ["train"]

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: True
  cate_dict_url: "/mnt/petrelfs/lirongjie/project/LAVIS/cache/psg/categories_dict.json"
  
  zeroshot_cfg:
    zs_triplets: '/mnt/petrelfs/lirongjie/project/LAVIS/cache/psg/zeroshot_triplet.pytorch'
    zs_predicate: [38, 17, 27, 45, 24, 32, 15, 9, 53, 29, 50, 21, 36, 13, 54, 22, 16, 44, 12, 25, 11, 41, 10, 1, 39]

