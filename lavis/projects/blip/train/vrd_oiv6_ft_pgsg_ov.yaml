 # Copyright (c) 2022, salesforce.com, inc.
 # All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

model:
  arch: blip_rel_detection_pgsg
  model_type: base_oiv6
  load_finetuned: False

  pretrained: "cache/ckpts/model_base_capfilt_large.pth"
  

  num_coord_bin: 640
  add_noise: False
  dump_pred: False

  max_txt_len: 512 # training time
  max_objects: 5
  max_pos_objects: 10
  mask_label_ratio: 0.0
  reduction: 'mean' # none mean

  prompt: "The visual scene of: "

  aux_close_classifier: False
  pos_adapter: True
  pos_adapter_conv: "none"

  top_k_ent_label_num: 2
  top_k_predicate_label_num: 5

  image_size: 224
  box_loss_weight: 1.2
  cate_dict_url: "cache/openimages/open-imagev6/annotations/categories_dict.json"


  post_proc_cfg:
    ent_ampl_scale: 3.0
    ent_temperature: 1.0
    rel_ampl_scale: 1.0
    rel_temperature: 1.0


datasets:
  oiv6_rel_detection_zs_pred: # name of the dataset builder
    vis_processor:
        train:
          name: "blip_det_image_train"
          image_size: 224
        eval:
          name: "blip_det_image_eval"
          image_size: 224
    text_processor:
        train:
          name: "blip_caption"
        eval:
          name: "blip_caption"

run:
  task: relation_detection
  # optimizer
  lr_sched: "linear_warmup_cosine_lr"
  init_lr: 1e-5
  min_lr: 1e-7
  weight_decay: 0.05
  max_epoch: 101

  special_lr_param: 
    - ["text_decoder.pos_encoder", 1e-4,  1e-4]
    - ["text_decoder.pos_decoder", 1e-4,  1e-4]
    - ["text_decoder.bbox_embed", 1e-4,  1e-4]
    - ["text_decoder.enc_input_proj", 1e-4,  1e-4]
    - ["text_decoder.ent_hs_input_proj", 1e-4,  1e-4]
    - ["text_decoder.bert.embeddings.word_embeddings", 1e-18, 0.05]

  batch_size_train: 20
  batch_size_eval: 28
  num_workers: 4

  save_epoch: 5

  max_len: 768
  min_len: 768

  # max_len: 2048 # inference time
  # min_len: 300
  num_beams: 1

  seed: 42
  output_dir: "output/BLIP/rel_detection_oiv6"

  experiments_mode: sggen # sggen sgcls
  generation_mode: sampling # sampling search

  amp: False
  resume_ckpt_path: null

  evaluate: False 
  train_splits: ["train"]
  # train_splits: ["train_zs_pred"]
  # train_splits: ["train_zs_ent_openvocab"]
  # valid_splits: ["val"]
  valid_splits: ["test"]
  test_splits: ["test"]

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: True
  cate_dict_url: "cache/openimages/open-imagev6/annotations/categories_dict.json"

  zeroshot_cfg:
    zs_triplets: "cache/openimages/open-imagev6/annotations/zeroshot_triplet.pytorch"
    zs_predicate: [8, 4, 28, 13, 22, 10, 3, 23, 7, 26, 27, 1]

